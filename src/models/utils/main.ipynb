{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.utils.sp_scraper import SPScraper\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "import talib as ta\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 20:59:12.713435: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-13 20:59:12.713463: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-13 20:59:12.713468: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744592352.713478  343581 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1744592352.713498  343581 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/model3.keras')\n",
    "\n",
    "# Load all scalers\n",
    "scaler_future_price = joblib.load('/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/scaler_future_price.pkl')\n",
    "scaler_ticker = joblib.load('/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/scaler_ticker.pkl')\n",
    "scaler_technical = joblib.load('/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/scaler_technical.pkl')\n",
    "\n",
    "# Initialize the scalers dictionary\n",
    "scalers = {}\n",
    "\n",
    "# Path to the scalers directory\n",
    "scalers_dir = '/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/scalers'\n",
    "\n",
    "# Loop through each ticker directory\n",
    "for ticker in os.listdir(scalers_dir):\n",
    "    ticker_path = os.path.join(scalers_dir, ticker)\n",
    "    if os.path.isdir(ticker_path):\n",
    "        # Load all three scalers for this ticker\n",
    "        scaler_close = joblib.load(os.path.join(ticker_path, 'scaler_close.pkl'))\n",
    "        scaler_sma_10 = joblib.load(os.path.join(ticker_path, 'scaler_sma_10.pkl'))\n",
    "        scaler_sma_30 = joblib.load(os.path.join(ticker_path, 'scaler_sma_30.pkl'))\n",
    "        \n",
    "        # Store them in a dictionary\n",
    "        scalers[ticker] = {\n",
    "            'scaler_close': scaler_close,\n",
    "            'scaler_sma_10': scaler_sma_10,\n",
    "            'scaler_sma_30': scaler_sma_30\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 504/504 [00:06<00:00, 81.70ticker/s] \n"
     ]
    }
   ],
   "source": [
    "# Replace '.' with '-' in ticker symbols, also add SPY as a benchmark\n",
    "scraper = SPScraper()\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scraper.scrape_sp500_symbols().index)] + [\"^GSPC\"]\n",
    "\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "def process_ticker(ticker):\n",
    "    try:\n",
    "        # Retry logic\n",
    "        while True:\n",
    "            try:\n",
    "                ticker_data = yf.Ticker(ticker).history(period=\"1y\")\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(10)\n",
    "\n",
    "        if ticker_data.empty:\n",
    "            return None\n",
    "\n",
    "        # Process data\n",
    "        ticker_data.reset_index(inplace=True)\n",
    "        ticker_data.columns = ticker_data.columns.str.lower()\n",
    "        ticker_data['ticker'] = ticker\n",
    "\n",
    "        ticker_data['rsi'] = ta.RSI(ticker_data['close'], timeperiod=14)\n",
    "        macd, macdsignal, macdhist = ta.MACD(ticker_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        ticker_data['macd'] = macd\n",
    "        ticker_data['sma_10'] = ta.SMA(ticker_data['close'], timeperiod=10)\n",
    "        ticker_data['sma_30'] = ta.SMA(ticker_data['close'], timeperiod=30)\n",
    "\n",
    "        # Initialize scalers\n",
    "        scaler_close = StandardScaler()\n",
    "        scaler_future_price = StandardScaler()\n",
    "        scaler_sma_10 = StandardScaler()\n",
    "        scaler_sma_30 = StandardScaler()\n",
    "\n",
    "        # Select and scale\n",
    "        close_vals = ticker_data[['close']].values\n",
    "        sma_10_vals = ticker_data[['sma_10']].values\n",
    "        sma_30_vals = ticker_data[['sma_30']].values\n",
    "\n",
    "        ticker_data['scaled_close'] = scalers[ticker]['scaler_close'].transform(close_vals)\n",
    "        ticker_data['scaled_sma_10'] = scalers[ticker]['scaler_sma_10'].transform(sma_10_vals)\n",
    "        ticker_data['scaled_sma_30'] = scalers[ticker]['scaler_sma_30'].transform(sma_30_vals)\n",
    "\n",
    "        # Save scalers\n",
    "        ticker_scalers = {\n",
    "            'scaler_close': scaler_close,\n",
    "            'scaler_sma_10': scaler_sma_10,\n",
    "            'scaler_sma_30': scaler_sma_30\n",
    "        }\n",
    "\n",
    "        return ticker_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use multithreading for I/O-bound operations like data download\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_ticker, ticker): ticker for ticker in sp_tickers}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading data\", unit=\"ticker\"):\n",
    "        result_data = future.result()\n",
    "        if result_data is not None:\n",
    "            data_frames.append(result_data)\n",
    "        else:\n",
    "            print(f\"Failed to process {future.result()}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "# Label encode the ticker column\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"encoded_ticker\"] = label_encoder.fit_transform(data[\"ticker\"])\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "scaler_technical = StandardScaler()\n",
    "\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"encoded_ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['scaled_ticker'] = scaled_ticker\n",
    "\n",
    "#scale technical columns\n",
    "stock_technical = data.filter([\"return\", \"rsi\", \"macd\"])\n",
    "stock_technical = stock_technical.values\n",
    "scaled_technicals = scaler_technical.fit_transform(stock_technical)\n",
    "# Insert scaled data into the original dataframe\n",
    "data['scaled_rsi'] = scaled_technicals[:, 0]\n",
    "data['scaled_macd'] = scaled_technicals[:, 1]\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')\n",
    "grouped_dfs = {ticker: df.sort_values(by='date').reset_index(drop=True) for ticker, df in grouped_dfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for date: 2025-04-11 00:00:00-04:00\n",
      "Top 10 Predicted Returns:\n",
      "Ticker | Predicted Return\n",
      "------------------------------\n",
      "TXT    |         16.06%\n",
      "PPG    |         15.21%\n",
      "TGT    |         15.15%\n",
      "OXY    |         14.62%\n",
      "WDC    |         14.58%\n",
      "ON     |         14.40%\n",
      "TMO    |         14.06%\n",
      "SWKS   |         13.98%\n",
      "MRK    |         13.80%\n",
      "FANG   |         13.78%\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['scaled_close', 'scaled_rsi', 'scaled_macd', 'scaled_sma_10', 'scaled_sma_30', 'scaled_ticker']\n",
    "\n",
    "#take curr day, find most recent day in each df\n",
    "today = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "x_pred = []\n",
    "for ticker, df in grouped_dfs.items():\n",
    "    most_recent_day = df['date'].max()\n",
    "    most_recent_index = df[df['date'] == most_recent_day].index[0]\n",
    "\n",
    "    window = df.iloc[most_recent_index - 60:][feature_cols].values\n",
    "\n",
    "    x_pred.append([ticker,window])\n",
    "\n",
    "#predicting based on the second vals of x_test (the windows)\n",
    "predictions = model.predict(np.array([x[1] for x in x_pred]))\n",
    "#inverting the scaling\n",
    "predictions = scaler_future_price.inverse_transform(predictions)\n",
    "# Assigning predictions, and real vals based on ticker\n",
    "predictions = {x_pred[i][0]: (float(predictions[i][0])) for i in range(len(predictions))}\n",
    "#sorting the predictions by the first value (the predicted vals)\n",
    "top_10_predictions = dict(sorted(predictions.items(), \n",
    "                                key=lambda x: x[1], \n",
    "                                reverse=True)[:10])\n",
    "clear_output(wait=True)  # The wait=True parameter prevents flickering\n",
    "print(f\"\\nPredictions for date: {most_recent_day}\")\n",
    "print(\"Top 10 Predicted Returns:\")\n",
    "print(\"Ticker | Predicted Return\")\n",
    "print(\"-\" * 30)\n",
    "for ticker, pred in top_10_predictions.items():\n",
    "# Convert to percentages by multiplying by 100\n",
    "    print(f\"{ticker:6} | {pred*100:13.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
