{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.utils.sp_scraper import scrape_sp500_symbols\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, BatchNormalization, LeakyReLU, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import talib as ta\n",
    "import time\n",
    "\n",
    "model = keras.models.load_model('/Users/aryanhazra/Downloads/VSCode Repos/trading_model/src/models/model3/model3.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.' with '-' in ticker symbols, also add SPY as a benchmark\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scrape_sp500_symbols())] + [\"^GSPC\"]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Initialize scaler dictionaries to store scalers for each ticker\n",
    "scalers = {}\n",
    "\n",
    "for ticker in tqdm(sp_tickers, desc = \"Downloading data\", unit=\"ticker\"):\n",
    "    # Initialize scalers\n",
    "    scaler_close = StandardScaler()\n",
    "    scaler_future_price = StandardScaler()\n",
    "    scaler_sma_10 = StandardScaler()\n",
    "    scaler_sma_30 = StandardScaler()\n",
    "\n",
    "\n",
    "    def get_ticker_data(ticker):\n",
    "        while True:\n",
    "            try:\n",
    "                # Get max data for the ticker\n",
    "                ticker_data = yf.Ticker(ticker).history(period=\"max\")\n",
    "                return ticker_data\n",
    "            except Exception as e:\n",
    "                time.sleep(10)\n",
    "                # Continue the loop to try again\n",
    "\n",
    "    # Usage - this will keep trying until successful\n",
    "    ticker_data = get_ticker_data(ticker)\n",
    "\n",
    "    # Make date a column instead of index\n",
    "    ticker_data.reset_index(inplace=True)\n",
    "\n",
    "    # Make columns lowercase\n",
    "    ticker_data.columns = ticker_data.columns.str.lower()\n",
    "\n",
    "    # Add a ticker column keep uppercase\n",
    "    ticker_data['ticker'] = ticker\n",
    "\n",
    "    # Add a price return in 30 days column\n",
    "    ticker_data['log_return_30d'] = np.log(ticker_data['close'].shift(-30) / ticker_data['close'])\n",
    "\n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    ticker_data['rsi'] = ta.RSI(ticker_data['close'], timeperiod=14)\n",
    "\n",
    "    # Calculate MACD (Moving Average Convergence Divergence)\n",
    "    macd, macdsignal, macdhist = ta.MACD(ticker_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    ticker_data['macd'] = macd  # MACD line\n",
    "\n",
    "    # Calculate SMA (Simple Moving Average) for 10 and 30 periods\n",
    "    ticker_data['sma_10'] = ta.SMA(ticker_data['close'], timeperiod=10)\n",
    "    ticker_data['sma_30'] = ta.SMA(ticker_data['close'], timeperiod=30)\n",
    "\n",
    "    # Scale close column\n",
    "    stock_close = ticker_data.filter([\"close\"])\n",
    "    stock_log_return_30d = ticker_data.filter([\"log_return_30d\"])\n",
    "    stock_sma_10 = ticker_data.filter([\"sma_10\"])   \n",
    "    stock_sma_30 = ticker_data.filter([\"sma_30\"])\n",
    "    # Convert to numpy array\n",
    "    stock_close = stock_close.values\n",
    "    stock_log_return_30d = stock_log_return_30d.values\n",
    "    stock_sma_10 = stock_sma_10.values\n",
    "    stock_sma_30 = stock_sma_30.values\n",
    "    # Scale the data\n",
    "    scaled_close = scaler_close.fit_transform(stock_close)\n",
    "    scaled_log_return_30d = scaler_future_price.fit_transform(stock_log_return_30d)\n",
    "    scaled_sma_10 = scaler_sma_10.fit_transform(stock_sma_10)\n",
    "    scaled_sma_30 = scaler_sma_30.fit_transform(stock_sma_30)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['scaled_close'] = scaled_close\n",
    "    ticker_data['scaled_log_return_30d'] = scaled_log_return_30d\n",
    "    ticker_data['scaled_sma_10'] = scaled_sma_10\n",
    "    ticker_data['scaled_sma_30'] = scaled_sma_30\n",
    "\n",
    "    # Store the scalers for the ticker\n",
    "    scalers[ticker] = {\n",
    "        'scaler_close': scaler_close,\n",
    "        'scaler_future_price': scaler_future_price,\n",
    "    }\n",
    "\n",
    "    # Concat the ticker data with the main data\n",
    "    data = pd.concat([data, ticker_data], ignore_index=True)\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "# Label encode the ticker column\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"encoded_ticker\"] = label_encoder.fit_transform(data[\"ticker\"])\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "scaler_technical = StandardScaler()\n",
    "\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"encoded_ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['scaled_ticker'] = scaled_ticker\n",
    "\n",
    "#scale technical columns\n",
    "stock_technical = data.filter([\"return\", \"rsi\", \"macd\"])\n",
    "stock_technical = stock_technical.values\n",
    "scaled_technicals = scaler_technical.fit_transform(stock_technical)\n",
    "# Insert scaled data into the original dataframe\n",
    "data['scaled_rsi'] = scaled_technicals[:, 0]\n",
    "data['scaled_macd'] = scaled_technicals[:, 1]\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your list of tuples is called ticker_df_list\n",
    "spy_data = next(df for ticker, df in grouped_dfs if ticker == \"^GSPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['scaled_close', 'scaled_rsi', 'scaled_macd', 'scaled_sma_10', 'scaled_sma_30', 'scaled_ticker']\n",
    "# Start on day 60 of SPY\n",
    "for i in tqdm(range(60, len(spy_data) - 30, 30), desc=\"Processing SPY data\", unit=\"step\"):\n",
    "    target_date = spy_data.iloc[i]['date']\n",
    "    x_test = []\n",
    "    y_real = []\n",
    "    predictions = {}\n",
    "    for ticker, df in grouped_dfs:\n",
    "        if ticker == \"^GSPC\":\n",
    "            print(\"SPY\")\n",
    "        df = df.sort_values(by='date').reset_index(drop=True)\n",
    "    \n",
    "        # Ensure target_date is timezone-naive\n",
    "        target_date = pd.to_datetime(target_date).replace(tzinfo=None)\n",
    "\n",
    "        # Ensure df['date'] is also timezone-naive\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "        # Now this check will work correctly\n",
    "        if target_date not in df['date'].values:\n",
    "            continue\n",
    "\n",
    "        date_idx = df.index[df['date'] == target_date][0]\n",
    "\n",
    "        # Check if there are 60 days before and 30 after\n",
    "        if not (date_idx >= 60 and date_idx + 30 < len(df)):\n",
    "            continue\n",
    "\n",
    "        window = df.iloc[date_idx - 60:date_idx][feature_cols].values  # shape (60, num_features)\n",
    "\n",
    "        x_test.append([ticker, window])\n",
    "\n",
    "        # Predict the \"price in 30 days\" from the current i-th index (i.e. day 60 of the window)\n",
    "        y_real.append(df.iloc[i]['log_return_30d'])\n",
    "\n",
    "    #predicting based on the second vals of x_test (the windows)\n",
    "    predictions = model.predict(np.array([x[1] for x in x_test]))\n",
    "    #inverting the scaling\n",
    "    predictions = scalers[x_test[0][0]]['scaler_future_price'].inverse_transform(predictions)\n",
    "    # Assigning predictions, and real vals based on ticker\n",
    "    predictions = {x_test[i][0]: (float(predictions[i][0]), float(y_real[i])) for i in range(len(predictions))}\n",
    "    #sorting the predictions by the first value (the predicted vals)\n",
    "    top_10_predictions = dict(sorted(predictions.items(), \n",
    "                                        key=lambda x: x[1][0], \n",
    "                                        reverse=True)[:10])\n",
    "    print(f\"\\nPredictions for date: {target_date}\")\n",
    "    print(\"Top 10 Predicted Returns:\")\n",
    "    print(\"Ticker | Predicted Return | Actual Return\")\n",
    "    print(\"-\" * 45)\n",
    "    for ticker, (pred, actual) in top_10_predictions.items():\n",
    "        print(f\"{ticker:6} | {pred:14.4f} | {actual:13.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
