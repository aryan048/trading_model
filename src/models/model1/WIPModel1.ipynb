{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 42868,
     "status": "ok",
     "timestamp": 1743736194799,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "i2f2zetSfwtm",
    "outputId": "b7fbd935-be65-4552-9006-6da0eeb70e25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.sp_scraper import scrape_sp500_symbols\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266955,
     "status": "ok",
     "timestamp": 1743736461751,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "dJg_o59ofwto",
    "outputId": "8e6c1605-54aa-4ee7-a242-825c49f71c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 503/503 [02:41<00:00,  3.11ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace '.' with '-' in ticker symbols\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scrape_sp500_symbols())]\n",
    "ticker_encoding = {ticker: i for i, ticker in enumerate(sp_tickers)}\n",
    "data = pd.DataFrame()\n",
    "for ticker in tqdm(sp_tickers, desc = \"Downloading data\", unit=\"ticker\"):\n",
    "    # Initialize scalers\n",
    "    scaler_close = StandardScaler()\n",
    "    scaler_future_price = StandardScaler()\n",
    "\n",
    "\n",
    "    # Get max data for the ticker\n",
    "    ticker_data = yf.Ticker(ticker).history(period=\"max\")\n",
    "\n",
    "    # Make data a column instead of index\n",
    "    ticker_data.reset_index(inplace=True)\n",
    "\n",
    "    # Make columns lowercase\n",
    "    ticker_data.columns = ticker_data.columns.str.lower()\n",
    "\n",
    "    # Add a price in 30 days column\n",
    "    ticker_data['price in 30 days'] = ticker_data['close'].shift(-30)\n",
    "\n",
    "    # Drop NA rows (last 30 days)\n",
    "    ticker_data.dropna(inplace=True)\n",
    "\n",
    "    # Replace a ticker column\n",
    "    ticker_data['ticker'] = ticker_encoding[ticker]\n",
    "\n",
    "    # Scale close column\n",
    "    stock_close = ticker_data.filter([\"close\"])\n",
    "    # Convert to numpy array\n",
    "    stock_close = stock_close.values\n",
    "    # Scale the data\n",
    "    scaled_close = scaler_close.fit_transform(stock_close)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['close'] = scaled_close\n",
    "\n",
    "    # Scale prediction column\n",
    "    stock_price_in_30_days = ticker_data.filter([\"price in 30 days\"])\n",
    "    # Convert to numpy array\n",
    "    stock_price_in_30_days = stock_price_in_30_days.values\n",
    "    # Scale the data\n",
    "    scaled_price_in_30_days = scaler_future_price.fit_transform(stock_price_in_30_days)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['price in 30 days'] = scaled_price_in_30_days\n",
    "\n",
    "    # Concat the ticker data with the main data\n",
    "    data = pd.concat([data, ticker_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743736461852,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "cXfl1NZ3fwtp"
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['ticker'] = scaled_ticker\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647844,
     "status": "ok",
     "timestamp": 1743737109698,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "ZDEglV1Qfwtq",
    "outputId": "6b4120d9-7479-4fca-ee87-a5f194b8e4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sliding windows: 100%|██████████| 503/503 [03:53<00:00,  2.15ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a sliding window for our stock (60 days in past to predict 30 days in future)\n",
    "x_train, y_train = [], []\n",
    "for ticker, df in tqdm(grouped_dfs, desc= \"Creating sliding windows\", unit=\"ticker\"):\n",
    "    # Sort df by date\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "\n",
    "    # Loop through the DataFrame to create sliding windows\n",
    "    for i in range(60, len(df) - 30):\n",
    "\n",
    "        # Get the past 60 close prices\n",
    "        close_prices = df.iloc[i - 60:i]['close'].values.reshape(-1, 1)  # shape (60, 1)\n",
    "\n",
    "        # Repeat the ticker value for each timestep\n",
    "        ticker_feature = np.full((60, 1), ticker)  # shape (60, 1)\n",
    "\n",
    "        # Combine features: shape will be (60, 2)\n",
    "        features = np.hstack((close_prices, ticker_feature))\n",
    "\n",
    "        # Append the full (60, 2) array to x_train\n",
    "        x_train.append(features)\n",
    "\n",
    "        # Append the 'price in 30 days' value at the 60th row to y_train\n",
    "        y_train.append(df.iloc[i]['price in 30 days'])\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape x_train to be 3D for LSTM input\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 118269,
     "status": "error",
     "timestamp": 1743737380050,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "DDhaCLfYfwtq",
    "outputId": "4b74729f-857e-494b-ef40-e92268c93b67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 23:39:15,322] A new study created in memory with name: no-name-f9b8a698-f0af-4c58-80cf-f829507fc577\n",
      "2025-04-03 23:39:15.467687: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-03 23:39:15.468213: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-03 23:39:15.468769: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743737955.469067   87472 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1743737955.469672   87472 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 23:39:44.188344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 26103/423532\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:41:42\u001b[0m 33ms/step - loss: 0.1155 - root_mean_squared_error: 0.1913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-04-03 23:54:20,551] Trial 0 failed with parameters: {'lstm_units_1': 512, 'lstm_units_2': 448, 'dense_units': 256, 'dropout_rate': 0.5656710988063212, 'learning_rate': 0.00014787390806528337, 'optimizer': 'rmsprop'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/sc/4kqdg3r12q5gsk451cb70kyr0000gn/T/ipykernel_2409/1744692887.py\", line 28, in objective\n",
      "    history = model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=8, callbacks=[early_stopping], verbose=1)\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "    if not opt_outputs.has_value():\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 321, in __bool__\n",
      "    x = self._numpy()\n",
      "  File \"/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 385, in _numpy\n",
      "    return self._numpy_internal()\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-03 23:54:20,559] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create an Optuna study\u001b[39;00m\n\u001b[1;32m     33\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Store best hyperparameters in a dictionary\u001b[39;00m\n\u001b[1;32m     37\u001b[0m best_hyperparams \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     26\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#large batch size because colab tpu can probably handle it\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:321\u001b[0m, in \u001b[0;36m_EagerTensorBase.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 321\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x)\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:385\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mArrayLike:\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"lstm_units_1\": trial.suggest_int('lstm_units_1', 64, 512, step=64),\n",
    "        \"lstm_units_2\": trial.suggest_int('lstm_units_2', 64, 512, step=64),\n",
    "        \"dense_units\": trial.suggest_int('dense_units', 64, 256, step=64),\n",
    "        \"dropout_rate\": trial.suggest_float('dropout_rate', 0.2, 0.7),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical('optimizer', ['adam', 'rmsprop']),\n",
    "    }\n",
    "\n",
    "    # Convert to tf.data.Dataset for efficient loading\n",
    "    batch_size = 8  # You can adjust this based on your memory capacity\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    \n",
    "    # Shuffle, batch, and prefetch the data\n",
    "    dataset = (dataset\n",
    "               .shuffle(buffer_size=10000)  # Buffer size for shuffling\n",
    "               .batch(batch_size)           # Batch size for training\n",
    "               .prefetch(tf.data.AUTOTUNE))  # Prefetch data to improve performance\n",
    "\n",
    "    # Build the model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(params[\"lstm_units_1\"], return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(keras.layers.LSTM(params[\"lstm_units_2\"], return_sequences=False))\n",
    "    model.add(keras.layers.Dense(params[\"dense_units\"], activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=params[\"learning_rate\"]) if params[\"optimizer\"] == 'adam' else keras.optimizers.RMSprop(learning_rate=params[\"learning_rate\"])\n",
    "    model.compile(optimizer=optimizer, loss=\"mae\", metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(dataset, validation_split=0.2, epochs=10, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Return the validation loss\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Store best hyperparameters in a dictionary\n",
    "best_hyperparams = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124244,
     "status": "aborted",
     "timestamp": 1743737210214,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "xgaQ4tDHfwtq"
   },
   "outputs": [],
   "source": [
    "# Store best hyperparameters in a dictionary\n",
    "best_hyperparams = study.best_params\n",
    "\n",
    "# Build model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(best_hyperparams[\"lstm_units_1\"], return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(keras.layers.LSTM(best_hyperparams[\"lstm_units_2\"], return_sequences=False))\n",
    "model.add(keras.layers.Dense(best_hyperparams[\"dense_units\"], activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(best_hyperparams[\"dropout_rate\"]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=best_hyperparams[\"learning_rate\"]) if best_hyperparams[\"optimizer\"] == 'adam' else keras.optimizers.RMSprop(learning_rate=best_hyperparams[\"learning_rate\"])\n",
    "model.compile(optimizer=optimizer, loss=\"mae\", metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with as many epochs as possible\n",
    "training = model.fit(x_train, y_train, epochs=1000, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "model.save(\"model1.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
