{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 42868,
     "status": "ok",
     "timestamp": 1743736194799,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "i2f2zetSfwtm",
    "outputId": "b7fbd935-be65-4552-9006-6da0eeb70e25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.sp_scraper import scrape_sp500_symbols\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "from optuna.integration import KerasPruningCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266955,
     "status": "ok",
     "timestamp": 1743736461751,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "dJg_o59ofwto",
    "outputId": "8e6c1605-54aa-4ee7-a242-825c49f71c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 503/503 [02:35<00:00,  3.24ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace '.' with '-' in ticker symbols\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scrape_sp500_symbols())]\n",
    "ticker_encoding = {ticker: i for i, ticker in enumerate(sp_tickers)}\n",
    "data = pd.DataFrame()\n",
    "# Initialize scaler dictionaries to store scalers for each ticker\n",
    "scalers = {}\n",
    "for ticker in tqdm(sp_tickers, desc = \"Downloading data\", unit=\"ticker\"):\n",
    "    # Initialize scalers\n",
    "    scaler_close = StandardScaler()\n",
    "    scaler_future_price = StandardScaler()\n",
    "\n",
    "\n",
    "    # Get max data for the ticker\n",
    "    ticker_data = yf.Ticker(ticker).history(period=\"max\")\n",
    "\n",
    "    # Make data a column instead of index\n",
    "    ticker_data.reset_index(inplace=True)\n",
    "\n",
    "    # Make columns lowercase\n",
    "    ticker_data.columns = ticker_data.columns.str.lower()\n",
    "\n",
    "    # Add a price in 30 days column\n",
    "    ticker_data['price in 30 days'] = ticker_data['close'].shift(-30)\n",
    "\n",
    "    # Drop NA rows (last 30 days)\n",
    "    ticker_data.dropna(inplace=True)\n",
    "\n",
    "    # Replace a ticker column\n",
    "    ticker_data['ticker'] = ticker_encoding[ticker]\n",
    "\n",
    "    # Scale close column\n",
    "    stock_close = ticker_data.filter([\"close\"])\n",
    "    # Convert to numpy array\n",
    "    stock_close = stock_close.values\n",
    "    # Scale the data\n",
    "    scaled_close = scaler_close.fit_transform(stock_close)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['close'] = scaled_close\n",
    "\n",
    "    # Scale prediction column\n",
    "    stock_price_in_30_days = ticker_data.filter([\"price in 30 days\"])\n",
    "    # Convert to numpy array\n",
    "    stock_price_in_30_days = stock_price_in_30_days.values\n",
    "    # Scale the data\n",
    "    scaled_price_in_30_days = scaler_future_price.fit_transform(stock_price_in_30_days)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['price in 30 days'] = scaled_price_in_30_days\n",
    "\n",
    "    # Store the scalers for the ticker\n",
    "    scalers[ticker] = {\n",
    "        'scaler_close': scaler_close,\n",
    "        'scaler_future_price': scaler_future_price\n",
    "    }\n",
    "\n",
    "    # Concat the ticker data with the main data\n",
    "    data = pd.concat([data, ticker_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743736461852,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "cXfl1NZ3fwtp"
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['ticker'] = scaled_ticker\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647844,
     "status": "ok",
     "timestamp": 1743737109698,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "ZDEglV1Qfwtq",
    "outputId": "6b4120d9-7479-4fca-ee87-a5f194b8e4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sliding windows: 100%|██████████| 503/503 [03:43<00:00,  2.25ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a sliding window for our stock (60 days in past to predict 30 days in future)\n",
    "x_train, y_train = [], []\n",
    "for ticker, df in tqdm(grouped_dfs, desc= \"Creating sliding windows\", unit=\"ticker\"):\n",
    "    # Sort df by date\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "\n",
    "    # Loop through the DataFrame to create sliding windows\n",
    "    for i in range(60, len(df) - 30):\n",
    "\n",
    "        # Get the past 60 close prices\n",
    "        close_prices = df.iloc[i - 60:i]['close'].values.reshape(-1, 1)  # shape (60, 1)\n",
    "\n",
    "        # Repeat the ticker value for each timestep\n",
    "        ticker_feature = np.full((60, 1), ticker)  # shape (60, 1)\n",
    "\n",
    "        # Combine features: shape will be (60, 2)\n",
    "        features = np.hstack((close_prices, ticker_feature))\n",
    "\n",
    "        # Append the full (60, 2) array to x_train\n",
    "        x_train.append(features)\n",
    "\n",
    "        # Append the 'price in 30 days' value at the 60th row to y_train\n",
    "        y_train.append(df.iloc[i]['price in 30 days'])\n",
    "\n",
    "# Convert x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape x_train to be 3D for LSTM input\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 118269,
     "status": "error",
     "timestamp": 1743737380050,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "DDhaCLfYfwtq",
    "outputId": "4b74729f-857e-494b-ef40-e92268c93b67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-04 00:17:51,164] A new study created in memory with name: no-name-79889b2b-b144-4d88-9619-f4dea7dab06a\n",
      "2025-04-04 00:17:51.315206: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-04 00:17:51.315868: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-04 00:17:51.316439: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743740271.316743  126383 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1743740271.317113  126383 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 00:17:59.765522: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250534/423532\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m53:37\u001b[0m 19ms/step - loss: 0.1341 - root_mean_squared_error: 0.2265"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"lstm_units_1\": trial.suggest_int('lstm_units_1', 64, 512, step=64),\n",
    "        \"lstm_units_2\": trial.suggest_int('lstm_units_2', 64, 512, step=64),\n",
    "        \"dense_units\": trial.suggest_int('dense_units', 64, 256, step=64),\n",
    "        \"dropout_rate\": trial.suggest_float('dropout_rate', 0.2, 0.7),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
    "        \"optimizer\": trial.suggest_categorical('optimizer', ['adam', 'rmsprop']),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    # Build the model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(params[\"lstm_units_1\"], return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(keras.layers.LSTM(params[\"lstm_units_2\"], return_sequences=False))\n",
    "    model.add(keras.layers.Dense(params[\"dense_units\"], activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=params[\"learning_rate\"]) if params[\"optimizer\"] == 'adam' else keras.optimizers.RMSprop(learning_rate=params[\"learning_rate\"])\n",
    "    model.compile(optimizer=optimizer, loss=\"mae\", metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    # Early stopping callback\n",
    "    pruning_callback = KerasPruningCallback(trial, 'val_loss')\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=10,\n",
    "        batch_size=8,\n",
    "        callbacks=[pruning_callback],  # Add pruning callback here\n",
    "        verbose=1\n",
    "    )\n",
    "    history = model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=8, callbacks=[pruning_callback], verbose=1)\n",
    "\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Store best hyperparameters in a dictionary\n",
    "best_hyperparams = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124244,
     "status": "aborted",
     "timestamp": 1743737210214,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "xgaQ4tDHfwtq"
   },
   "outputs": [],
   "source": [
    "# Store best hyperparameters in a dictionary\n",
    "best_hyperparams = study.best_params\n",
    "\n",
    "# Build model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(best_hyperparams[\"lstm_units_1\"], return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(keras.layers.LSTM(best_hyperparams[\"lstm_units_2\"], return_sequences=False))\n",
    "model.add(keras.layers.Dense(best_hyperparams[\"dense_units\"], activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(best_hyperparams[\"dropout_rate\"]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=best_hyperparams[\"learning_rate\"]) if best_hyperparams[\"optimizer\"] == 'adam' else keras.optimizers.RMSprop(learning_rate=best_hyperparams[\"learning_rate\"])\n",
    "model.compile(optimizer=optimizer, loss=\"mae\", metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with as many epochs as possible\n",
    "training = model.fit(x_train, y_train, epochs=1000, batch_size=8, callbacks=[early_stopping])\n",
    "\n",
    "model.save(\"model1.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
