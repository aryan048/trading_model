{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 42868,
     "status": "ok",
     "timestamp": 1743736194799,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "i2f2zetSfwtm",
    "outputId": "b7fbd935-be65-4552-9006-6da0eeb70e25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.sp_scraper import scrape_sp500_symbols\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "from optuna.integration import KerasPruningCallback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, BatchNormalization, LeakyReLU, Dropout\n",
    "import talib as ta\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266955,
     "status": "ok",
     "timestamp": 1743736461751,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "dJg_o59ofwto",
    "outputId": "8e6c1605-54aa-4ee7-a242-825c49f71c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:   0%|          | 0/503 [00:01<?, ?ticker/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m ticker_data\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Assuming ticker_data is a DataFrame with 'Close' column\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m ticker_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mticker_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mpct_change()  \u001b[38;5;66;03m# Percentage change in close prices\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate RSI (Relative Strength Index)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m ticker_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrsi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mRSI(ticker_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], timeperiod\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'"
     ]
    }
   ],
   "source": [
    "# Replace '.' with '-' in ticker symbols\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scrape_sp500_symbols())]\n",
    "ticker_encoding = {ticker: i for i, ticker in enumerate(sp_tickers)}\n",
    "data = pd.DataFrame()\n",
    "# Initialize scaler dictionaries to store scalers for each ticker\n",
    "scalers = {}\n",
    "for ticker in tqdm(sp_tickers, desc = \"Downloading data\", unit=\"ticker\"):\n",
    "    # Initialize scalers\n",
    "    scaler_close = StandardScaler()\n",
    "    scaler_future_price = StandardScaler()\n",
    "    scaler_technical = StandardScaler()\n",
    "\n",
    "\n",
    "    # Get max data for the ticker\n",
    "    def get_ticker_data(ticker):\n",
    "        # Get max data for the ticker\n",
    "        ticker_data = yf.Ticker(ticker).history(period=\"1y\")\n",
    "        return ticker_data\n",
    "\n",
    "    try:\n",
    "        # Get ticker data\n",
    "        ticker_data = get_ticker_data(ticker)\n",
    "    except:\n",
    "        time.sleep(10)\n",
    "        ticker_data = get_ticker_data(ticker)\n",
    "\n",
    "    # Make date a column instead of index\n",
    "    ticker_data.reset_index(inplace=True)\n",
    "\n",
    "    # Make columns lowercase\n",
    "    ticker_data.columns = ticker_data.columns.str.lower()\n",
    "\n",
    "    # Add a price in 30 days column\n",
    "    ticker_data['price in 30 days'] = ticker_data['close'].shift(-30)\n",
    "\n",
    "    # Assuming ticker_data is a DataFrame with 'Close' column\n",
    "    ticker_data['return'] = ticker_data['close'].pct_change()  # Percentage change in close prices\n",
    "\n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    ticker_data['rsi'] = ta.RSI(ticker_data['close'], timeperiod=14)\n",
    "\n",
    "    # Calculate MACD (Moving Average Convergence Divergence)\n",
    "    macd, macdsignal, macdhist = ta.MACD(ticker_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    ticker_data['macd'] = macd  # MACD line\n",
    "\n",
    "    # Calculate SMA (Simple Moving Average) for 10 and 30 periods\n",
    "    ticker_data['sma_10'] = ta.SMA(ticker_data['close'], timeperiod=10)\n",
    "    ticker_data['sma_30'] = ta.SMA(ticker_data['close'], timeperiod=30)\n",
    "\n",
    "    # Select the relevant technical columns\n",
    "    stock_technicals = ticker_data[['return', 'rsi', 'macd', 'sma_10', 'sma_30']]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    stock_technicals = stock_technicals.values\n",
    "    # Scale the data\n",
    "    scaled_technicals = scaler_technical.fit_transform(stock_technicals)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['return'] = scaled_technicals[:, 0]\n",
    "    ticker_data['rsi'] = scaled_technicals[:, 1]\n",
    "    ticker_data['macd'] = scaled_technicals[:, 2]\n",
    "    ticker_data['sma_10'] = scaled_technicals[:, 3]\n",
    "    ticker_data['sma_30'] = scaled_technicals[:, 4]\n",
    "\n",
    "    # Replace a ticker column\n",
    "    ticker_data['ticker'] = ticker_encoding[ticker]\n",
    "\n",
    "    # Scale close column\n",
    "    stock_close = ticker_data.filter([\"close\"])\n",
    "    # Convert to numpy array\n",
    "    stock_close = stock_close.values\n",
    "    # Scale the data\n",
    "    scaled_close = scaler_close.fit_transform(stock_close)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['close'] = scaled_close\n",
    "\n",
    "    # Scale prediction column\n",
    "    stock_price_in_30_days = ticker_data.filter([\"price in 30 days\"])\n",
    "    # Convert to numpy array\n",
    "    stock_price_in_30_days = stock_price_in_30_days.values\n",
    "    # Scale the data\n",
    "    scaled_price_in_30_days = scaler_future_price.fit_transform(stock_price_in_30_days)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['price in 30 days'] = scaled_price_in_30_days\n",
    "\n",
    "    # Store the scalers for the ticker\n",
    "    scalers[ticker] = {\n",
    "        'scaler_close': scaler_close,\n",
    "        'scaler_future_price': scaler_future_price,\n",
    "        'scaler_technical': scaler_technical\n",
    "    }\n",
    "\n",
    "    # Concat the ticker data with the main data\n",
    "    data = pd.concat([data, ticker_data], ignore_index=True)\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743736461852,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "cXfl1NZ3fwtp"
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['ticker'] = scaled_ticker\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647844,
     "status": "ok",
     "timestamp": 1743737109698,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "ZDEglV1Qfwtq",
    "outputId": "6b4120d9-7479-4fca-ee87-a5f194b8e4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sliding windows: 100%|██████████| 503/503 [00:03<00:00, 140.14ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# List the features you want to include (excluding 'price in 30 days' and 'date')\n",
    "feature_cols = ['close', 'rsi', 'macd', 'sma_10', 'sma_30', 'ticker']  # add your actual column names here\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for ticker, df in tqdm(grouped_dfs, desc=\"Creating sliding windows\", unit=\"ticker\"):\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    \n",
    "    # Ensure no NaNs (especially if you used rolling indicators like SMA, RSI)\n",
    "    df = df.dropna(subset=feature_cols + ['price in 30 days'])\n",
    "\n",
    "    for i in range(60, len(df) - 30):\n",
    "        # Extract a sliding window of all desired features\n",
    "        window = df.iloc[i - 60:i][feature_cols].values  # shape (60, num_features)\n",
    "\n",
    "        # Optional: add ticker as a numeric value if it's useful\n",
    "        # ticker_id = your_ticker_encoding[ticker]  # if you're using one-hot or label encoding\n",
    "        # ticker_column = np.full((60, 1), ticker_id)\n",
    "        # window = np.hstack((window, ticker_column))\n",
    "\n",
    "        x_train.append(window)\n",
    "\n",
    "        # Predict the \"price in 30 days\" from the current i-th index (i.e. day 60 of the window)\n",
    "        y_train.append(df.iloc[i]['price in 30 days'])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124244,
     "status": "aborted",
     "timestamp": 1743737210214,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "xgaQ4tDHfwtq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 00:21:00.056478: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-07 00:21:00.056546: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-07 00:21:00.056567: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743999660.056970  148051 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1743999660.057173  148051 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m34,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,465</span> (619.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,465\u001b[0m (619.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,209</span> (618.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,209\u001b[0m (618.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 00:21:00.783959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 49ms/step - loss: 0.7568 - root_mean_squared_error: 0.8119 - val_loss: 0.6326 - val_root_mean_squared_error: 0.7992\n",
      "Epoch 2/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.6096 - root_mean_squared_error: 0.7646 - val_loss: 0.6320 - val_root_mean_squared_error: 0.7896\n",
      "Epoch 3/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 49ms/step - loss: 0.5945 - root_mean_squared_error: 0.7503 - val_loss: 0.6243 - val_root_mean_squared_error: 0.7966\n",
      "Epoch 4/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 49ms/step - loss: 0.5783 - root_mean_squared_error: 0.7321 - val_loss: 0.6011 - val_root_mean_squared_error: 0.7597\n",
      "Epoch 5/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.5632 - root_mean_squared_error: 0.7168 - val_loss: 0.6090 - val_root_mean_squared_error: 0.7801\n",
      "Epoch 6/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.5479 - root_mean_squared_error: 0.7026 - val_loss: 0.6273 - val_root_mean_squared_error: 0.7962\n",
      "Epoch 7/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.5354 - root_mean_squared_error: 0.6917 - val_loss: 0.6205 - val_root_mean_squared_error: 0.7975\n",
      "Epoch 8/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.5214 - root_mean_squared_error: 0.6747 - val_loss: 0.6335 - val_root_mean_squared_error: 0.8043\n",
      "Epoch 9/200\n",
      "\u001b[1m7406/7406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - loss: 0.5000 - root_mean_squared_error: 0.6497 - val_loss: 0.6350 - val_root_mean_squared_error: 0.8126\n"
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=keras.losses.Huber(),\n",
    "              metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\n",
    "lr_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                factor=0.5, \n",
    "                                                patience=3, \n",
    "                                                verbose=1)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           patience=10, \n",
    "                                           restore_best_weights=True)\n",
    "\n",
    "training = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200,                # Max number of epochs\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,      # Use part of training data for validation\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "model.save(\"model1.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
