{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 42868,
     "status": "ok",
     "timestamp": 1743736194799,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "i2f2zetSfwtm",
    "outputId": "b7fbd935-be65-4552-9006-6da0eeb70e25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.utils.sp_scraper import SPScraper\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, BatchNormalization, LeakyReLU, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import talib as ta\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266955,
     "status": "ok",
     "timestamp": 1743736461751,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "dJg_o59ofwto",
    "outputId": "8e6c1605-54aa-4ee7-a242-825c49f71c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 504/504 [00:06<00:00, 80.54ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace '.' with '-' in ticker symbols, also add SPY as a benchmark\n",
    "scraper = SPScraper()\n",
    "\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scraper.scrape_sp500_symbols().index)] + [\"^GSPC\"]\n",
    "scalers = {}\n",
    "data_frames = []\n",
    "\n",
    "def process_ticker(ticker):\n",
    "    try:\n",
    "        # Retry logic\n",
    "        while True:\n",
    "            try:\n",
    "                ticker_data = yf.Ticker(ticker).history(period=\"1y\")\n",
    "                break\n",
    "            except Exception:\n",
    "                time.sleep(10)\n",
    "\n",
    "        if ticker_data.empty:\n",
    "            return None, None\n",
    "\n",
    "        # Process data\n",
    "        ticker_data.reset_index(inplace=True)\n",
    "        ticker_data.columns = ticker_data.columns.str.lower()\n",
    "        ticker_data['ticker'] = ticker\n",
    "        ticker_data['log_return_30d'] = np.log(ticker_data['close'].shift(-30) / ticker_data['close'])\n",
    "\n",
    "        ticker_data['rsi'] = ta.RSI(ticker_data['close'], timeperiod=14)\n",
    "        macd, macdsignal, macdhist = ta.MACD(ticker_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        ticker_data['macd'] = macd\n",
    "        ticker_data['sma_10'] = ta.SMA(ticker_data['close'], timeperiod=10)\n",
    "        ticker_data['sma_30'] = ta.SMA(ticker_data['close'], timeperiod=30)\n",
    "\n",
    "        # Initialize scalers\n",
    "        scaler_close = StandardScaler()\n",
    "        scaler_sma_10 = StandardScaler()\n",
    "        scaler_sma_30 = StandardScaler()\n",
    "\n",
    "        # Select and scale\n",
    "        close_vals = ticker_data[['close']].values\n",
    "        sma_10_vals = ticker_data[['sma_10']].values\n",
    "        sma_30_vals = ticker_data[['sma_30']].values\n",
    "\n",
    "        ticker_data['scaled_close'] = scaler_close.fit_transform(close_vals)\n",
    "        ticker_data['scaled_sma_10'] = scaler_sma_10.fit_transform(sma_10_vals)\n",
    "        ticker_data['scaled_sma_30'] = scaler_sma_30.fit_transform(sma_30_vals)\n",
    "\n",
    "        # Save scalers\n",
    "        ticker_scalers = {\n",
    "            'scaler_close': scaler_close,\n",
    "            'scaler_sma_10': scaler_sma_10,\n",
    "            'scaler_sma_30': scaler_sma_30\n",
    "        }\n",
    "        \n",
    "\n",
    "        return ticker_data, (ticker, ticker_scalers)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {ticker}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Use multithreading for I/O-bound operations like data download\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_ticker, ticker): ticker for ticker in sp_tickers}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading data\", unit=\"ticker\"):\n",
    "        result_data, result_scalers = future.result()\n",
    "        if result_data is not None:\n",
    "            data_frames.append(result_data)\n",
    "        else:\n",
    "            print(f\"Failed to process {future.result()}\")\n",
    "        if result_scalers is not None:\n",
    "            ticker, scaler_dict = result_scalers\n",
    "            scalers[ticker] = scaler_dict\n",
    "        else:\n",
    "            print(f\"Failed to process {future.result()}\")\n",
    "\n",
    "# After the ThreadPoolExecutor block, add this code:\n",
    "# Save all scalers\n",
    "for ticker, scaler_dict in scalers.items():\n",
    "    # Create ticker-specific directory\n",
    "    ticker_dir = os.path.join('scalers', ticker)\n",
    "    os.makedirs(ticker_dir, exist_ok=True)\n",
    "    \n",
    "    # Save each scaler in the ticker's directory\n",
    "    for scaler_name, scaler in scaler_dict.items():\n",
    "        joblib.dump(scaler, os.path.join(ticker_dir, f'{scaler_name}.pkl'))\n",
    "\n",
    "# Combine all dataframes\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743736461852,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "cXfl1NZ3fwtp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_future_price.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data for the model\n",
    "# Label encode the ticker column\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"encoded_ticker\"] = label_encoder.fit_transform(data[\"ticker\"])\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "scaler_technical = StandardScaler()\n",
    "scaler_future_price = StandardScaler()\n",
    "\n",
    "# Scale future price\n",
    "log_return_vals = data[['log_return_30d']].values\n",
    "data['scaled_log_return_30d'] = scaler_future_price.fit_transform(log_return_vals)\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"encoded_ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['scaled_ticker'] = scaled_ticker\n",
    "\n",
    "#scale technical columns\n",
    "stock_technical = data.filter([\"return\", \"rsi\", \"macd\"])\n",
    "stock_technical = stock_technical.values\n",
    "scaled_technicals = scaler_technical.fit_transform(stock_technical)\n",
    "# Insert scaled data into the original dataframe\n",
    "data['scaled_rsi'] = scaled_technicals[:, 0]\n",
    "data['scaled_macd'] = scaled_technicals[:, 1]\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')\n",
    "grouped_dfs = {ticker: df.sort_values(by='date').reset_index(drop=True) for ticker, df in grouped_dfs}\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(scaler_ticker, \"scaler_ticker.pkl\")\n",
    "joblib.dump(scaler_technical, \"scaler_technical.pkl\")\n",
    "joblib.dump(scaler_future_price, \"scaler_future_price.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647844,
     "status": "ok",
     "timestamp": 1743737109698,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "ZDEglV1Qfwtq",
    "outputId": "6b4120d9-7479-4fca-ee87-a5f194b8e4be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sliding windows: 100%|██████████| 504/504 [00:07<00:00, 67.36ticker/s]\n"
     ]
    }
   ],
   "source": [
    "# List the features you want to include (excluding 'price in 30 days' and 'date')\n",
    "# scaled_close, scaled_sma's are scaled by ticker, rest by total df\n",
    "feature_cols = ['scaled_close', 'scaled_rsi', 'scaled_macd', 'scaled_sma_10', 'scaled_sma_30', 'scaled_ticker']  # add your actual column names here\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for ticker, df in tqdm(grouped_dfs.items(), desc=\"Creating sliding windows\", unit=\"ticker\"):\n",
    "\n",
    "    if len(df) < 91:\n",
    "        continue\n",
    "    \n",
    "    for i in range(60, len(df) - 30):\n",
    "        # Extract a sliding window of all desired features\n",
    "        window = df.iloc[i - 60:i][feature_cols].values  # shape (60, num_features)\n",
    "\n",
    "        # Optional: add ticker as a numeric value if it's useful\n",
    "        # ticker_id = your_ticker_encoding[ticker]  # if you're using one-hot or label encoding\n",
    "        # ticker_column = np.full((60, 1), ticker_id)\n",
    "        # window = np.hstack((window, ticker_column))\n",
    "\n",
    "        x_train.append(window)\n",
    "\n",
    "        # Predict the \"price in 30 days\" from the current i-th index (i.e. day 60 of the window)\n",
    "        y_train.append(df.iloc[i]['scaled_log_return_30d'])\n",
    "        \n",
    "# Convert to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124244,
     "status": "aborted",
     "timestamp": 1743737210214,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "xgaQ4tDHfwtq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-13 20:26:17.477082: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-13 20:26:17.477273: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-04-13 20:26:17.477585: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744590377.477886  285574 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1744590377.478282  285574 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/aryanhazra/Downloads/VSCode Repos/trading_model/.venv/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m1,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,777</span> (796.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,777\u001b[0m (796.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,521</span> (795.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,521\u001b[0m (795.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 20:26:18.739308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 91ms/step - loss: 0.4733 - root_mean_squared_error: 0.8600 - val_loss: 0.2917 - val_root_mean_squared_error: 0.7508\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers for local pattern extraction\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Stacked Bidirectional LSTM for capturing sequence relationships\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense layers for final nonlinear transformation\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.4))  # Slightly increased dropout to reduce overfitting\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1))  # Output log return prediction\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss=keras.losses.Huber(delta=1.0),  # Huber = better for stability on noisy targets\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "\n",
    "lr_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                factor=0.5, \n",
    "                                                patience=3, \n",
    "                                                verbose=1)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           patience=10, \n",
    "                                           restore_best_weights=True)\n",
    "\n",
    "training = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200,                # Max number of epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,      # Use part of training data for validation\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "model.save(\"model3.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
