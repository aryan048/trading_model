{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 42868,
     "status": "ok",
     "timestamp": 1743736194799,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "i2f2zetSfwtm",
    "outputId": "b7fbd935-be65-4552-9006-6da0eeb70e25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.utils.sp_scraper import scrape_sp500_symbols\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, BatchNormalization, LeakyReLU, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import talib as ta\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266955,
     "status": "ok",
     "timestamp": 1743736461751,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "dJg_o59ofwto",
    "outputId": "8e6c1605-54aa-4ee7-a242-825c49f71c68"
   },
   "outputs": [],
   "source": [
    "# Replace '.' with '-' in ticker symbols, also add SPY as a benchmark\n",
    "sp_tickers = [ticker.replace(\".\", \"-\") for ticker in sorted(scrape_sp500_symbols())] + [\"^GSPC\"]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Initialize scaler dictionaries to store scalers for each ticker\n",
    "scalers = {}\n",
    "\n",
    "for ticker in tqdm(sp_tickers, desc = \"Downloading data\", unit=\"ticker\"):\n",
    "    # Initialize scalers\n",
    "    scaler_close = StandardScaler()\n",
    "    scaler_future_price = StandardScaler()\n",
    "    scaler_sma_10 = StandardScaler()\n",
    "    scaler_sma_30 = StandardScaler()\n",
    "\n",
    "\n",
    "    def get_ticker_data(ticker):\n",
    "        while True:\n",
    "            try:\n",
    "                # Get max data for the ticker\n",
    "                ticker_data = yf.Ticker(ticker).history(period=\"1y\")\n",
    "                return ticker_data\n",
    "            except Exception as e:\n",
    "                time.sleep(10)\n",
    "                # Continue the loop to try again\n",
    "\n",
    "    # Usage - this will keep trying until successful\n",
    "    ticker_data = get_ticker_data(ticker)\n",
    "\n",
    "    # Make date a column instead of index\n",
    "    ticker_data.reset_index(inplace=True)\n",
    "\n",
    "    # Make columns lowercase\n",
    "    ticker_data.columns = ticker_data.columns.str.lower()\n",
    "\n",
    "    # Add a ticker column keep uppercase\n",
    "    ticker_data['ticker'] = ticker\n",
    "\n",
    "    # Add a price return in 30 days column\n",
    "    ticker_data['log_return_30d'] = np.log(ticker_data['close'].shift(-30) / ticker_data['close'])\n",
    "\n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    ticker_data['rsi'] = ta.RSI(ticker_data['close'], timeperiod=14)\n",
    "\n",
    "    # Calculate MACD (Moving Average Convergence Divergence)\n",
    "    macd, macdsignal, macdhist = ta.MACD(ticker_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    ticker_data['macd'] = macd  # MACD line\n",
    "\n",
    "    # Calculate SMA (Simple Moving Average) for 10 and 30 periods\n",
    "    ticker_data['sma_10'] = ta.SMA(ticker_data['close'], timeperiod=10)\n",
    "    ticker_data['sma_30'] = ta.SMA(ticker_data['close'], timeperiod=30)\n",
    "\n",
    "    # Scale close column\n",
    "    stock_close = ticker_data.filter([\"close\"])\n",
    "    stock_log_return_30d = ticker_data.filter([\"log_return_30d\"])\n",
    "    stock_sma_10 = ticker_data.filter([\"sma_10\"])   \n",
    "    stock_sma_30 = ticker_data.filter([\"sma_30\"])\n",
    "    # Convert to numpy array\n",
    "    stock_close = stock_close.values\n",
    "    stock_log_return_30d = stock_log_return_30d.values\n",
    "    stock_sma_10 = stock_sma_10.values\n",
    "    stock_sma_30 = stock_sma_30.values\n",
    "    # Scale the data\n",
    "    scaled_close = scaler_close.fit_transform(stock_close)\n",
    "    scaled_log_return_30d = scaler_future_price.fit_transform(stock_log_return_30d)\n",
    "    scaled_sma_10 = scaler_sma_10.fit_transform(stock_sma_10)\n",
    "    scaled_sma_30 = scaler_sma_30.fit_transform(stock_sma_30)\n",
    "    # Insert scaled data into the original dataframe\n",
    "    ticker_data['scaled_close'] = scaled_close\n",
    "    ticker_data['scaled_log_return_30d'] = scaled_log_return_30d\n",
    "    ticker_data['scaled_sma_10'] = scaled_sma_10\n",
    "    ticker_data['scaled_sma_30'] = scaled_sma_30\n",
    "\n",
    "    # Store the scalers for the ticker\n",
    "    scalers[ticker] = {\n",
    "        'scaler_close': scaler_close,\n",
    "        'scaler_future_price': scaler_future_price,\n",
    "        'scaler_sma_10': scaler_sma_10,\n",
    "        'scaler_sma_30': scaler_sma_30\n",
    "    }\n",
    "\n",
    "    # Concat the ticker data with the main data\n",
    "    data = pd.concat([data, ticker_data], ignore_index=True)\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743736461852,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "cXfl1NZ3fwtp"
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "# Label encode the ticker column\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"encoded_ticker\"] = label_encoder.fit_transform(data[\"ticker\"])\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_ticker = StandardScaler()\n",
    "scaler_technical = StandardScaler()\n",
    "\n",
    "\n",
    "# Scale the ticker column\n",
    "stock_ticker = data.filter([\"encoded_ticker\"])\n",
    "stock_ticker = stock_ticker.values\n",
    "scaled_ticker = scaler_ticker.fit_transform(stock_ticker)\n",
    "data['scaled_ticker'] = scaled_ticker\n",
    "\n",
    "#scale technical columns\n",
    "stock_technical = data.filter([\"return\", \"rsi\", \"macd\"])\n",
    "stock_technical = stock_technical.values\n",
    "scaled_technicals = scaler_technical.fit_transform(stock_technical)\n",
    "# Insert scaled data into the original dataframe\n",
    "data['scaled_rsi'] = scaled_technicals[:, 0]\n",
    "data['scaled_macd'] = scaled_technicals[:, 1]\n",
    "\n",
    "# Group the data by ticker\n",
    "grouped_dfs = data.groupby('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647844,
     "status": "ok",
     "timestamp": 1743737109698,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "ZDEglV1Qfwtq",
    "outputId": "6b4120d9-7479-4fca-ee87-a5f194b8e4be"
   },
   "outputs": [],
   "source": [
    "# List the features you want to include (excluding 'price in 30 days' and 'date')\n",
    "# scaled_close, scaled_sma's are scaled by ticker, rest by total df\n",
    "feature_cols = ['scaled_close', 'scaled_rsi', 'scaled_macd', 'scaled_sma_10', 'scaled_sma_30', 'scaled_ticker']  # add your actual column names here\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for ticker, df in tqdm(grouped_dfs, desc=\"Creating sliding windows\", unit=\"ticker\"):\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "\n",
    "    for i in range(60, len(df) - 30):\n",
    "        # Extract a sliding window of all desired features\n",
    "        window = df.iloc[i - 60:i][feature_cols].values  # shape (60, num_features)\n",
    "\n",
    "        # Optional: add ticker as a numeric value if it's useful\n",
    "        # ticker_id = your_ticker_encoding[ticker]  # if you're using one-hot or label encoding\n",
    "        # ticker_column = np.full((60, 1), ticker_id)\n",
    "        # window = np.hstack((window, ticker_column))\n",
    "\n",
    "        x_train.append(window)\n",
    "\n",
    "        # Predict the \"price in 30 days\" from the current i-th index (i.e. day 60 of the window)\n",
    "        y_train.append(df.iloc[i]['scaled_log_return_30d'])\n",
    "        \n",
    "# Convert to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1124244,
     "status": "aborted",
     "timestamp": 1743737210214,
     "user": {
      "displayName": "Aryan Hazra",
      "userId": "11477684992723650711"
     },
     "user_tz": 240
    },
    "id": "xgaQ4tDHfwtq"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers for local pattern extraction\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Stacked Bidirectional LSTM for capturing sequence relationships\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense layers for final nonlinear transformation\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.4))  # Slightly increased dropout to reduce overfitting\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1))  # Output log return prediction\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss=keras.losses.Huber(delta=1.0),  # Huber = better for stability on noisy targets\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "\n",
    "lr_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                factor=0.5, \n",
    "                                                patience=3, \n",
    "                                                verbose=1)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           patience=10, \n",
    "                                           restore_best_weights=True)\n",
    "\n",
    "training = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200,                # Max number of epochs\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,      # Use part of training data for validation\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "model.save(\"model3.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
